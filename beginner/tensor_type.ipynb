{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic data type\n",
    "**All is about Tensor**\n",
    "\n",
    "|python|PyTorch|\n",
    "|---|---|\n",
    "|Int|IntTensor of size()|\n",
    "|float|FloatTensor of size()|\n",
    "|Int array|IntTensor of size [d1,d2,...]|\n",
    "|Float array|FloatTensor of size [d1,d2,...]|\n",
    "|string|--|\n",
    "\n",
    "#### How to denote string\n",
    "- One-hot\n",
    "- Embedding\n",
    "\n",
    "### Data type\n",
    "|Data type|dtype|CPU tensor|GPU tensor|\n",
    "|---|---|---|---|\n",
    "|32-bit floating point|`torch.float32`or`torch.float`|`torch.FloatTensor`|`torch.cuda.FloatTensor`|\n",
    "|64-bit floating point|`torch.float64`or`torch.double`|`torch.DoubleTensor`|`torch.cuda.DoubleTensor`|\n",
    "|16-bit floating point|`torch.float16`or`torch.half`|`torch.HalfTensor`|`torch.cuda.HalfTensor`|\n",
    "|8-bit integer point (unsigned)|`torch.uint8`|`torch.ByteTensor`|`torch.cuda.ByteTensor`|\n",
    "|8-bit integer point (signed)|`torch.int8`|`torch.CharTensor`|`torch.cuda.CharTensor`|\n",
    "|16-bit integer point (signed)|`torch.int16`or`torch.short`|`torch.ShortTensor`|`torch.cuda.ShortTensor`|\n",
    "|32-bit integer point (signed)|`torch.int32`or`torch.int`|`torch.IntTensor`|`torch.cuda.IntTensor`|\n",
    "|64-bit integer point (signed)|`torch.int64`or`torch.long`|`torch.LongTensor`|`torch.cuda.LongTensor`|\n",
    "\n",
    "### Type check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "<class 'torch.Tensor'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(2, 3)\n",
    "print(a.type())\n",
    "print(type(a))\n",
    "print(isinstance(a, torch.FloatTensor))  # parameter type validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`a` is a 2-dim tensor with the size 2x3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# data type are different in gpu\n",
    "import torch\n",
    "\n",
    "data = torch.DoubleTensor(2, 3)\n",
    "print(isinstance(data, torch.cuda.DoubleTensor))\n",
    "data = data.cuda()\n",
    "print(isinstance(data, torch.cuda.DoubleTensor))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dimension 0 / rank 0\n",
    "**scalar**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.3000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor(1.))\n",
    "print(torch.tensor(1.3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.tensor(1.3)` is a 0-dim scalar, whereas `torch.tensor([1.3])` is a 1-dim, 1-sized **Tensor**<br>\n",
    "**loss** 经常用0维张量表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(2.2)\n",
    "print(data.shape)\n",
    "print(len(data.shape))\n",
    "print(data.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dimension 1 / rank 1\n",
    "**vector**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1000])\n",
      "tensor([1.1000, 2.2000])\n",
      "tensor([-7.9386e-10])\n",
      "tensor([-7.9384e-10,  3.0662e-41])\n",
      "[1. 1.]\n",
      "tensor([1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.tensor([1.1]))\n",
    "print(torch.tensor([1.1, 2.2]))\n",
    "print(torch.FloatTensor(1))\n",
    "print(torch.FloatTensor(2))\n",
    "data = np.ones(2)\n",
    "print(data)\n",
    "print(torch.from_numpy(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Attention**:\n",
    "- `torch.tensor()` takes in data item\n",
    "- `torch.FloatTensor()` takes in data shape, initialized randomly, or data item wrapped with `[item]`\n",
    "\n",
    "**Bias, Linear Input** 经常用1维张量表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dimension 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3900,  0.3228,  2.0778],\n",
      "        [ 0.0510, -0.9101,  0.0500]])\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(2, 3)\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(data.size(0))\n",
    "print(data.size(1))\n",
    "print(data.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Linear Input Batch** 经常用2维张量表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dimension 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3193, 0.8452, 0.5259]],\n",
      "\n",
      "        [[0.1395, 0.3114, 0.1656]]])\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[0.3193, 0.8452, 0.5259]])\n",
      "[2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(2, 1, 3)\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(data[0])\n",
    "print(list(data.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RNN Input Batch** 经常用2维张量表示\n",
    "### Dimension 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[7.9020e-01, 9.2412e-01, 1.2545e-02,  ..., 4.0728e-01,\n",
      "           5.4756e-01, 4.0401e-01],\n",
      "          [8.1836e-01, 9.5927e-01, 3.7657e-01,  ..., 7.0206e-02,\n",
      "           2.6442e-01, 2.5098e-01],\n",
      "          [6.6138e-01, 3.1906e-01, 8.5082e-01,  ..., 9.2735e-01,\n",
      "           1.7698e-01, 2.6664e-01],\n",
      "          ...,\n",
      "          [2.6504e-01, 8.1270e-01, 2.6049e-02,  ..., 2.4965e-01,\n",
      "           7.1566e-02, 6.2901e-01],\n",
      "          [1.0624e-01, 7.6288e-01, 6.8958e-01,  ..., 3.0468e-01,\n",
      "           1.3646e-01, 6.6147e-01],\n",
      "          [8.2556e-01, 9.5165e-01, 9.2430e-02,  ..., 4.7954e-01,\n",
      "           1.8112e-01, 9.6573e-01]],\n",
      "\n",
      "         [[6.3637e-01, 6.9372e-01, 2.5479e-01,  ..., 8.6715e-01,\n",
      "           4.7054e-01, 5.4061e-01],\n",
      "          [3.9575e-01, 5.0156e-01, 5.0081e-01,  ..., 7.5456e-01,\n",
      "           6.4379e-04, 1.2794e-01],\n",
      "          [5.0436e-01, 4.7143e-01, 6.4827e-01,  ..., 3.4795e-02,\n",
      "           8.0159e-01, 9.7851e-01],\n",
      "          ...,\n",
      "          [3.5056e-01, 6.9816e-01, 2.7687e-01,  ..., 5.9365e-01,\n",
      "           6.7716e-01, 3.3981e-01],\n",
      "          [5.7224e-01, 3.3516e-01, 3.5967e-01,  ..., 7.0989e-01,\n",
      "           8.6690e-01, 2.6304e-01],\n",
      "          [3.5023e-01, 4.6282e-01, 6.2225e-01,  ..., 2.5833e-01,\n",
      "           3.5793e-01, 6.5201e-01]],\n",
      "\n",
      "         [[8.0022e-01, 6.0051e-01, 2.1708e-01,  ..., 4.6863e-01,\n",
      "           8.3811e-01, 7.1021e-01],\n",
      "          [6.9188e-01, 8.0482e-03, 3.6819e-02,  ..., 9.5394e-01,\n",
      "           9.7686e-01, 7.8896e-01],\n",
      "          [6.3983e-01, 8.6660e-01, 8.0660e-01,  ..., 3.5395e-01,\n",
      "           3.4216e-01, 2.3707e-01],\n",
      "          ...,\n",
      "          [6.2263e-01, 8.2755e-01, 8.9578e-01,  ..., 3.8723e-01,\n",
      "           1.3843e-02, 4.6527e-02],\n",
      "          [9.1247e-01, 6.2948e-02, 4.0590e-01,  ..., 3.4073e-01,\n",
      "           8.5306e-01, 5.1130e-01],\n",
      "          [4.8280e-01, 6.9458e-01, 4.9453e-01,  ..., 1.6323e-01,\n",
      "           6.6183e-01, 8.3399e-01]]],\n",
      "\n",
      "\n",
      "        [[[6.3961e-02, 3.4533e-01, 4.0225e-01,  ..., 6.4523e-01,\n",
      "           4.0667e-01, 4.5972e-01],\n",
      "          [3.1724e-02, 9.6322e-01, 9.5156e-01,  ..., 9.5813e-01,\n",
      "           9.8958e-01, 4.1867e-01],\n",
      "          [2.9987e-01, 3.8623e-01, 3.3263e-01,  ..., 4.7735e-02,\n",
      "           5.9772e-01, 2.3887e-01],\n",
      "          ...,\n",
      "          [7.9109e-01, 9.4790e-01, 4.2831e-01,  ..., 2.9296e-01,\n",
      "           7.8890e-01, 9.8058e-02],\n",
      "          [4.9300e-01, 4.8421e-01, 2.2309e-01,  ..., 2.9010e-02,\n",
      "           3.1511e-01, 8.5816e-01],\n",
      "          [1.4609e-01, 4.4883e-01, 7.6420e-01,  ..., 9.5708e-01,\n",
      "           9.2501e-01, 2.8529e-01]],\n",
      "\n",
      "         [[3.3702e-02, 2.8382e-01, 6.7092e-01,  ..., 3.2937e-02,\n",
      "           5.7130e-01, 6.8555e-01],\n",
      "          [8.9185e-01, 3.0017e-01, 6.8002e-01,  ..., 7.2089e-01,\n",
      "           7.8150e-01, 3.0865e-01],\n",
      "          [3.7352e-01, 8.3413e-01, 3.8778e-01,  ..., 7.4847e-01,\n",
      "           9.2947e-01, 4.9498e-01],\n",
      "          ...,\n",
      "          [3.6079e-01, 8.2245e-01, 8.5559e-01,  ..., 2.2706e-01,\n",
      "           9.6077e-01, 4.4352e-01],\n",
      "          [5.6722e-02, 3.1582e-01, 2.0919e-01,  ..., 4.6505e-02,\n",
      "           6.8015e-01, 3.8416e-01],\n",
      "          [4.2143e-01, 3.8065e-01, 3.2891e-01,  ..., 2.2635e-01,\n",
      "           1.1878e-01, 9.9549e-01]],\n",
      "\n",
      "         [[7.5656e-02, 4.1178e-01, 2.2621e-01,  ..., 6.5292e-01,\n",
      "           1.4866e-01, 6.4897e-01],\n",
      "          [3.7541e-01, 6.4073e-01, 6.8647e-01,  ..., 7.7202e-01,\n",
      "           9.5581e-01, 7.1039e-01],\n",
      "          [3.0258e-01, 8.3265e-01, 9.5625e-01,  ..., 9.5621e-01,\n",
      "           5.0897e-01, 7.9170e-01],\n",
      "          ...,\n",
      "          [7.3209e-01, 7.2008e-02, 9.5198e-01,  ..., 4.1331e-01,\n",
      "           7.7898e-01, 9.0896e-01],\n",
      "          [2.4592e-01, 6.4698e-01, 4.3051e-01,  ..., 7.7437e-01,\n",
      "           4.4685e-01, 9.7314e-01],\n",
      "          [7.8267e-01, 7.2857e-01, 9.7665e-01,  ..., 7.9495e-01,\n",
      "           8.0058e-01, 2.9799e-01]]]])\n",
      "torch.Size([2, 3, 28, 28])\n",
      "tensor([[[7.9020e-01, 9.2412e-01, 1.2545e-02,  ..., 4.0728e-01,\n",
      "          5.4756e-01, 4.0401e-01],\n",
      "         [8.1836e-01, 9.5927e-01, 3.7657e-01,  ..., 7.0206e-02,\n",
      "          2.6442e-01, 2.5098e-01],\n",
      "         [6.6138e-01, 3.1906e-01, 8.5082e-01,  ..., 9.2735e-01,\n",
      "          1.7698e-01, 2.6664e-01],\n",
      "         ...,\n",
      "         [2.6504e-01, 8.1270e-01, 2.6049e-02,  ..., 2.4965e-01,\n",
      "          7.1566e-02, 6.2901e-01],\n",
      "         [1.0624e-01, 7.6288e-01, 6.8958e-01,  ..., 3.0468e-01,\n",
      "          1.3646e-01, 6.6147e-01],\n",
      "         [8.2556e-01, 9.5165e-01, 9.2430e-02,  ..., 4.7954e-01,\n",
      "          1.8112e-01, 9.6573e-01]],\n",
      "\n",
      "        [[6.3637e-01, 6.9372e-01, 2.5479e-01,  ..., 8.6715e-01,\n",
      "          4.7054e-01, 5.4061e-01],\n",
      "         [3.9575e-01, 5.0156e-01, 5.0081e-01,  ..., 7.5456e-01,\n",
      "          6.4379e-04, 1.2794e-01],\n",
      "         [5.0436e-01, 4.7143e-01, 6.4827e-01,  ..., 3.4795e-02,\n",
      "          8.0159e-01, 9.7851e-01],\n",
      "         ...,\n",
      "         [3.5056e-01, 6.9816e-01, 2.7687e-01,  ..., 5.9365e-01,\n",
      "          6.7716e-01, 3.3981e-01],\n",
      "         [5.7224e-01, 3.3516e-01, 3.5967e-01,  ..., 7.0989e-01,\n",
      "          8.6690e-01, 2.6304e-01],\n",
      "         [3.5023e-01, 4.6282e-01, 6.2225e-01,  ..., 2.5833e-01,\n",
      "          3.5793e-01, 6.5201e-01]],\n",
      "\n",
      "        [[8.0022e-01, 6.0051e-01, 2.1708e-01,  ..., 4.6863e-01,\n",
      "          8.3811e-01, 7.1021e-01],\n",
      "         [6.9188e-01, 8.0482e-03, 3.6819e-02,  ..., 9.5394e-01,\n",
      "          9.7686e-01, 7.8896e-01],\n",
      "         [6.3983e-01, 8.6660e-01, 8.0660e-01,  ..., 3.5395e-01,\n",
      "          3.4216e-01, 2.3707e-01],\n",
      "         ...,\n",
      "         [6.2263e-01, 8.2755e-01, 8.9578e-01,  ..., 3.8723e-01,\n",
      "          1.3843e-02, 4.6527e-02],\n",
      "         [9.1247e-01, 6.2948e-02, 4.0590e-01,  ..., 3.4073e-01,\n",
      "          8.5306e-01, 5.1130e-01],\n",
      "         [4.8280e-01, 6.9458e-01, 4.9453e-01,  ..., 1.6323e-01,\n",
      "          6.6183e-01, 8.3399e-01]]])\n",
      "[2, 3, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(2, 3, 28, 28)\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(data[0])\n",
    "print(list(data.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Image** 经常用2维张量表示: `[batch_size,channel,height,width]`\n",
    "### Mixed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 28, 28])\n",
      "4704\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(2, 3, 28, 28)\n",
    "print(data.shape)\n",
    "print(data.numel())  # number of element\n",
    "print(data.dim())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Tensor\n",
    "### Import from numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.3000], dtype=torch.float64)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = np.array([2, 3.3])\n",
    "print(torch.from_numpy(data))\n",
    "data = np.ones([2, 3])\n",
    "print(torch.from_numpy(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import from List"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.2000])\n",
      "tensor([2.0000, 3.2000])\n",
      "tensor([[ 2.0000,  3.2000],\n",
      "        [ 1.0000, 22.3000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([2., 3.2]))\n",
    "print(torch.FloatTensor([2., 3.2]))\n",
    "print(torch.tensor([[2., 3.2], [1., 22.3]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Uninitialized data\n",
    "- `torch.empty(l)`\n",
    "- `torch.FloatTensor(d1,d2,d3)`\n",
    "- `torch.IntTensor(d1,d2,d3)`\n",
    "### Set default type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1.2, 3]).type())\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(torch.tensor([1.2, 3]).type())\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`double` type is usually used in **Reinforcement Learning**, whereas `float` type is used otherwise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rand / rand_like, randint\n",
    "- `[0,1)`\n",
    "- `[min, max)`\n",
    "- *_like"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2482, 0.3893, 0.8060],\n",
      "        [0.0617, 0.8547, 0.0323],\n",
      "        [0.4225, 0.2367, 0.9361]])\n",
      "tensor([[0.6445, 0.2877, 0.2359],\n",
      "        [0.8700, 0.3187, 0.8145],\n",
      "        [0.1740, 0.6938, 0.0955]])\n",
      "tensor([[2, 7, 5],\n",
      "        [4, 2, 2],\n",
      "        [3, 5, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 3)\n",
    "print(a)\n",
    "print(torch.rand_like(a))\n",
    "print(torch.randint(1, 10, [3, 3]))  # [1,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### randn\n",
    "- N(0,1)\n",
    "- N(u,std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3538, -0.9255, -0.5808],\n",
      "        [-0.4653, -0.6337,  1.1070],\n",
      "        [-1.0155,  0.8418, -0.6310]])\n",
      "tensor([[ 1.0734,  2.2591,  4.8391],\n",
      "        [ 3.9824,  6.0406,  3.8260],\n",
      "        [-1.1887,  2.0839,  3.7081]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.randn(3, 3))\n",
    "print(torch.normal(mean=torch.full([9], 3.0), std=torch.full([9], 2.0)).view(3, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### full"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.full([2, 3], 7.))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### arange/range\n",
    "### linspace/logspace\n",
    "### ones/zeros/eye\n",
    "### randperm: random.shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 2, 4, 9, 0, 5, 6, 1, 7, 3])\n",
      "tensor([[0.2991, 0.8423, 0.6147],\n",
      "        [0.1951, 0.9974, 0.6566]]) \n",
      " tensor([[0.3686, 0.3086],\n",
      "        [0.6662, 0.3752]])\n",
      "tensor([1, 0])\n",
      "tensor([[0.1951, 0.9974, 0.6566],\n",
      "        [0.2991, 0.8423, 0.6147]]) \n",
      " tensor([[0.6662, 0.3752],\n",
      "        [0.3686, 0.3086]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.randperm(10))\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(2, 2)\n",
    "print(a, '\\n', b)\n",
    "idx = torch.randperm(2)\n",
    "print(idx)\n",
    "print(a[idx], '\\n', b[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indexing and Slice\n",
    "### Indexing\n",
    "- dim 0 first"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([28, 28])\n",
      "tensor(0.4916)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(4, 3, 28, 28)\n",
    "print(data[0].shape)\n",
    "print(data[0, 0].shape)\n",
    "print(data[0, 0, 2, 4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### select first/last N\n",
    "use **`:`**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([2, 2, 28, 28])\n",
      "torch.Size([2, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(4, 3, 28, 28)\n",
    "print(data[:2].shape)\n",
    "print(data[:2, :1, :, :].shape)\n",
    "print(data[:2, 1:, :, :].shape)\n",
    "print(data[:2, -1:, :, :].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### select by steps\n",
    "```\n",
    "start:end:step\n",
    "```\n",
    "### select by specific index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7088, 0.3793, 0.4470,  ..., 0.3573, 0.3908, 0.5766],\n",
      "          [0.6455, 0.8977, 0.5200,  ..., 0.9006, 0.9129, 0.1650],\n",
      "          [0.6583, 0.6642, 0.1869,  ..., 0.8427, 0.2104, 0.4289],\n",
      "          ...,\n",
      "          [0.8010, 0.7757, 0.6833,  ..., 0.7287, 0.8546, 0.6893],\n",
      "          [0.7575, 0.3833, 0.8530,  ..., 0.8193, 0.8495, 0.7231],\n",
      "          [0.0432, 0.8897, 0.9249,  ..., 0.1218, 0.9154, 0.4881]],\n",
      "\n",
      "         [[0.2005, 0.5213, 0.9345,  ..., 0.3974, 0.0960, 0.4001],\n",
      "          [0.9628, 0.4946, 0.6078,  ..., 0.2566, 0.5435, 0.6679],\n",
      "          [0.2166, 0.0384, 0.7543,  ..., 0.6260, 0.4738, 0.8203],\n",
      "          ...,\n",
      "          [0.0226, 0.6026, 0.6478,  ..., 0.6894, 0.3150, 0.4137],\n",
      "          [0.0216, 0.0967, 0.7428,  ..., 0.1063, 0.4162, 0.0745],\n",
      "          [0.0060, 0.3569, 0.5468,  ..., 0.7573, 0.5379, 0.4131]],\n",
      "\n",
      "         [[0.7357, 0.9472, 0.9805,  ..., 0.1981, 0.8496, 0.1147],\n",
      "          [0.9601, 0.7892, 0.8236,  ..., 0.1969, 0.9379, 0.2697],\n",
      "          [0.7427, 0.1160, 0.2293,  ..., 0.8663, 0.9306, 0.3507],\n",
      "          ...,\n",
      "          [0.8482, 0.0266, 0.1350,  ..., 0.3364, 0.9653, 0.9419],\n",
      "          [0.1362, 0.8178, 0.6264,  ..., 0.8650, 0.2810, 0.3839],\n",
      "          [0.9274, 0.9743, 0.5435,  ..., 0.2151, 0.7632, 0.5016]]],\n",
      "\n",
      "\n",
      "        [[[0.5831, 0.8518, 0.7297,  ..., 0.6557, 0.2648, 0.3615],\n",
      "          [0.4473, 0.6161, 0.8341,  ..., 0.7296, 0.7709, 0.0263],\n",
      "          [0.5681, 0.1647, 0.9194,  ..., 0.9543, 0.0811, 0.9392],\n",
      "          ...,\n",
      "          [0.1687, 0.7866, 0.4673,  ..., 0.5863, 0.8595, 0.0722],\n",
      "          [0.4191, 0.5048, 0.6391,  ..., 0.4873, 0.3014, 0.1874],\n",
      "          [0.2643, 0.4490, 0.1580,  ..., 0.0039, 0.9535, 0.6013]],\n",
      "\n",
      "         [[0.3902, 0.7833, 0.9738,  ..., 0.6225, 0.2839, 0.5021],\n",
      "          [0.1147, 0.3752, 0.0447,  ..., 0.0258, 0.6271, 0.8170],\n",
      "          [0.2163, 0.0505, 0.3625,  ..., 0.6311, 0.8466, 0.8845],\n",
      "          ...,\n",
      "          [0.6820, 0.4505, 0.8833,  ..., 0.1436, 0.2013, 0.6464],\n",
      "          [0.7963, 0.8080, 0.8732,  ..., 0.9357, 0.3838, 0.1131],\n",
      "          [0.7554, 0.0112, 0.5363,  ..., 0.9097, 0.6652, 0.1371]],\n",
      "\n",
      "         [[0.7867, 0.3460, 0.2405,  ..., 0.6551, 0.2994, 0.9824],\n",
      "          [0.3971, 0.9145, 0.4725,  ..., 0.9842, 0.0187, 0.7251],\n",
      "          [0.0646, 0.7842, 0.5395,  ..., 0.3065, 0.8563, 0.0312],\n",
      "          ...,\n",
      "          [0.3669, 0.4673, 0.7884,  ..., 0.0142, 0.5629, 0.3386],\n",
      "          [0.4419, 0.7317, 0.5493,  ..., 0.6076, 0.2238, 0.6328],\n",
      "          [0.2518, 0.6459, 0.6398,  ..., 0.9726, 0.0924, 0.1048]]]])\n",
      "tensor([[[[0.2005, 0.5213, 0.9345,  ..., 0.3974, 0.0960, 0.4001],\n",
      "          [0.9628, 0.4946, 0.6078,  ..., 0.2566, 0.5435, 0.6679],\n",
      "          [0.2166, 0.0384, 0.7543,  ..., 0.6260, 0.4738, 0.8203],\n",
      "          ...,\n",
      "          [0.0226, 0.6026, 0.6478,  ..., 0.6894, 0.3150, 0.4137],\n",
      "          [0.0216, 0.0967, 0.7428,  ..., 0.1063, 0.4162, 0.0745],\n",
      "          [0.0060, 0.3569, 0.5468,  ..., 0.7573, 0.5379, 0.4131]],\n",
      "\n",
      "         [[0.7357, 0.9472, 0.9805,  ..., 0.1981, 0.8496, 0.1147],\n",
      "          [0.9601, 0.7892, 0.8236,  ..., 0.1969, 0.9379, 0.2697],\n",
      "          [0.7427, 0.1160, 0.2293,  ..., 0.8663, 0.9306, 0.3507],\n",
      "          ...,\n",
      "          [0.8482, 0.0266, 0.1350,  ..., 0.3364, 0.9653, 0.9419],\n",
      "          [0.1362, 0.8178, 0.6264,  ..., 0.8650, 0.2810, 0.3839],\n",
      "          [0.9274, 0.9743, 0.5435,  ..., 0.2151, 0.7632, 0.5016]]],\n",
      "\n",
      "\n",
      "        [[[0.4988, 0.4680, 0.5754,  ..., 0.1773, 0.6612, 0.7800],\n",
      "          [0.9423, 0.9239, 0.4212,  ..., 0.6670, 0.4507, 0.3302],\n",
      "          [0.5745, 0.2141, 0.7086,  ..., 0.0200, 0.5928, 0.3833],\n",
      "          ...,\n",
      "          [0.0811, 0.4844, 0.2111,  ..., 0.2716, 0.4482, 0.8371],\n",
      "          [0.7278, 0.6882, 0.1252,  ..., 0.6584, 0.4501, 0.5569],\n",
      "          [0.0554, 0.1655, 0.9424,  ..., 0.7832, 0.4046, 0.8381]],\n",
      "\n",
      "         [[0.8690, 0.7748, 0.5754,  ..., 0.3823, 0.0954, 0.6331],\n",
      "          [0.1155, 0.3856, 0.1074,  ..., 0.5851, 0.6911, 0.2950],\n",
      "          [0.7595, 0.1052, 0.2043,  ..., 0.7530, 0.6487, 0.2653],\n",
      "          ...,\n",
      "          [0.1945, 0.7845, 0.2547,  ..., 0.0862, 0.3322, 0.3227],\n",
      "          [0.6050, 0.5623, 0.0860,  ..., 0.5951, 0.4211, 0.7082],\n",
      "          [0.1771, 0.6560, 0.7985,  ..., 0.0880, 0.9529, 0.5747]]],\n",
      "\n",
      "\n",
      "        [[[0.3902, 0.7833, 0.9738,  ..., 0.6225, 0.2839, 0.5021],\n",
      "          [0.1147, 0.3752, 0.0447,  ..., 0.0258, 0.6271, 0.8170],\n",
      "          [0.2163, 0.0505, 0.3625,  ..., 0.6311, 0.8466, 0.8845],\n",
      "          ...,\n",
      "          [0.6820, 0.4505, 0.8833,  ..., 0.1436, 0.2013, 0.6464],\n",
      "          [0.7963, 0.8080, 0.8732,  ..., 0.9357, 0.3838, 0.1131],\n",
      "          [0.7554, 0.0112, 0.5363,  ..., 0.9097, 0.6652, 0.1371]],\n",
      "\n",
      "         [[0.7867, 0.3460, 0.2405,  ..., 0.6551, 0.2994, 0.9824],\n",
      "          [0.3971, 0.9145, 0.4725,  ..., 0.9842, 0.0187, 0.7251],\n",
      "          [0.0646, 0.7842, 0.5395,  ..., 0.3065, 0.8563, 0.0312],\n",
      "          ...,\n",
      "          [0.3669, 0.4673, 0.7884,  ..., 0.0142, 0.5629, 0.3386],\n",
      "          [0.4419, 0.7317, 0.5493,  ..., 0.6076, 0.2238, 0.6328],\n",
      "          [0.2518, 0.6459, 0.6398,  ..., 0.9726, 0.0924, 0.1048]]],\n",
      "\n",
      "\n",
      "        [[[0.8682, 0.4488, 0.0426,  ..., 0.7045, 0.7896, 0.1793],\n",
      "          [0.9851, 0.2296, 0.4446,  ..., 0.4671, 0.8491, 0.9449],\n",
      "          [0.1895, 0.1007, 0.2534,  ..., 0.7490, 0.0191, 0.6611],\n",
      "          ...,\n",
      "          [0.9529, 0.8484, 0.9394,  ..., 0.1148, 0.1062, 0.9727],\n",
      "          [0.1609, 0.7360, 0.4469,  ..., 0.9433, 0.6632, 0.8594],\n",
      "          [0.3151, 0.9949, 0.8670,  ..., 0.7234, 0.8525, 0.9158]],\n",
      "\n",
      "         [[0.7999, 0.9904, 0.1331,  ..., 0.4153, 0.3203, 0.8746],\n",
      "          [0.9645, 0.9699, 0.2427,  ..., 0.0929, 0.8721, 0.1226],\n",
      "          [0.3609, 0.9019, 0.2908,  ..., 0.5364, 0.2419, 0.3875],\n",
      "          ...,\n",
      "          [0.1593, 0.1141, 0.2756,  ..., 0.9653, 0.0721, 0.0342],\n",
      "          [0.8292, 0.9840, 0.4361,  ..., 0.8098, 0.1018, 0.5205],\n",
      "          [0.5033, 0.8471, 0.9019,  ..., 0.1917, 0.5127, 0.6008]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(4, 3, 28, 28)\n",
    "print(data.index_select(0, torch.tensor([0, 2])))  # select the 0th and 2nd image in the batch (dim 0)\n",
    "print(data.index_select(1, torch.tensor([1, 2])))  # select the 1st and 2nd channel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ... (dots)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(4, 3, 28, 28)\n",
    "print(data[...].shape)\n",
    "print(data[:, 1, ...].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*... is just for convenience*\n",
    "### select by mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5994,  0.7768,  1.1631, -0.4760],\n",
      "        [ 0.1112, -0.4026,  0.0910, -0.1785],\n",
      "        [ 0.5317,  0.6668, -1.0157,  1.3639]])\n",
      "tensor([[False,  True,  True, False],\n",
      "        [False, False, False, False],\n",
      "        [ True,  True, False,  True]])\n",
      "tensor([0.7768, 1.1631, 0.5317, 0.6668, 1.3639])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(3, 4)\n",
    "print(data)\n",
    "mask = data.ge(0.5)  # greater than or equal to\n",
    "print(mask)\n",
    "print(torch.masked_select(data, mask))  # reshape automatically to dim 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### select by flatten index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7062, -0.2849,  0.8619, -0.7494],\n",
      "        [ 1.9935, -0.5579, -0.1603, -1.4519],\n",
      "        [ 0.8707,  0.8974,  0.5575,  1.3623]])\n",
      "tensor([-0.7062,  0.8619, -0.5579])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(3, 4)\n",
    "print(data)\n",
    "print(torch.take(data, torch.tensor([0, 2, 5])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimension reshape\n",
    "### Operation\n",
    "- view/reshape: lost dim information"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 784])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(4, 3, 28, 28)\n",
    "print(data.view(4 * 3, 28 * 28).shape)  # numel must be equal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- squeeze/unsqueeze"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 28, 28])\n",
      "torch.Size([4, 3, 28, 28, 1])\n",
      "torch.Size([4, 3, 28, 28, 1])\n",
      "torch.Size([4, 1, 3, 28, 28])\n",
      "torch.Size([1, 4, 3, 28, 28])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([1, 32, 1])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.randn(4, 3, 28, 28)\n",
    "# unsqueeze: insert one index\n",
    "print(data.unsqueeze(0).shape)\n",
    "print(data.unsqueeze(-1).shape)\n",
    "print(data.unsqueeze(4).shape)\n",
    "print(data.unsqueeze(-4).shape)\n",
    "print(data.unsqueeze(-5).shape)\n",
    "# print(data.unsqueeze(5).shape) # IndexError: Dimension out of range (expected to be in range of [-5, 4], but got 5)\n",
    "\n",
    "# an example: add bias to image batch\n",
    "bias = torch.rand(32)\n",
    "# imgs = torch.rand(4, 32, 14, 14)\n",
    "bias = bias.unsqueeze(1).unsqueeze(2).unsqueeze(0)\n",
    "print(bias.shape)\n",
    "# now imgs+bias is OK\n",
    "# expand will be shown later\n",
    "# squeeze: delete one index\n",
    "print(bias.squeeze().shape)  # delete as more as possible (where dim index=1)\n",
    "print(bias.squeeze(0).shape)\n",
    "print(bias.squeeze(-1).shape)\n",
    "print(bias.squeeze(1).shape)  # dim 1 cannot be deleted\n",
    "print(bias.squeeze(-4).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- expand/repeat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 14, 14])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([1, 32, 1, -4])\n",
      "torch.Size([4, 32, 14, 14])\n",
      "torch.Size([4, 1024, 1, 1])\n",
      "torch.Size([4, 32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# expand: broadcasting, do not add new data, recommended\n",
    "imgs = torch.rand(4, 32, 14, 14)\n",
    "bias = torch.rand(1, 32, 1, 1)\n",
    "# src ===> dest\n",
    "# 1. share dimension\n",
    "# 2. src index should = 1\n",
    "print(bias.expand(4, 32, 14, 14).shape)\n",
    "print(bias.expand(-1, 32, -1, -1).shape)\n",
    "print(bias.expand(-1, 32, -1, -4).shape)  # nonsense\n",
    "after = imgs + bias.expand(4, 32, 14, 14)\n",
    "print(after.shape)\n",
    "\n",
    "# repeat: memory copied, copy existing data\n",
    "# attention: api is a bit different\n",
    "print(bias.repeat(4, 32, 1, 1).shape)  # wrong\n",
    "print(bias.repeat(4, 1, 1, 1).shape)  # correct"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- transpose/t/permute"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6442, 0.7168, 0.9299],\n",
      "        [0.7354, 0.5221, 0.6724],\n",
      "        [0.4489, 0.8888, 0.7132]])\n",
      "tensor([[0.6442, 0.7354, 0.4489],\n",
      "        [0.7168, 0.5221, 0.8888],\n",
      "        [0.9299, 0.6724, 0.7132]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 3)\n",
    "print(a)\n",
    "print(a.t())\n",
    "# t() expects a 2D tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 32, 3])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 32, 28, 3])\n",
      "torch.Size([4, 28, 32, 3])\n",
      "torch.Size([4, 28, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.rand(4, 3, 32, 32)\n",
    "# transpose is to swap dim\n",
    "# [b,c,h,w] ===> [b,w,h,c]\n",
    "# be careful!\n",
    "print(data.transpose(1, 3).shape)\n",
    "print(data.transpose(1, 3).contiguous().view(4, 3 * 32 * 32).view(4, 32, 32, 3).transpose(1, 3).shape)\n",
    "# permute\n",
    "# [b,c,h,w] ===> [b,h,w,c]\n",
    "data = torch.rand(4, 3, 28, 32)\n",
    "data_t = data.transpose(1, 3)\n",
    "print(data_t.shape)\n",
    "print(data_t.transpose(1, 2).shape)\n",
    "# can be finished by permute in one line:\n",
    "print(data.permute(0, 2, 3, 1).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Broadcasting\n",
    "### key idea\n",
    "1. insert 1 dim ahead\n",
    "2. expand dims with size 1 t same size\n",
    "\n",
    "example:\n",
    "- feature maps: [4,32,14,14]\n",
    "- bias: [32,1,1] ==> [1,32,1,1] ==> [4,32,14,14]\n",
    "\n",
    "### why broadcasting\n",
    "1. for actual demand\n",
    "    - [class,students,scores]\n",
    "    - add bias for every student: +5 score\n",
    "    - [4,32,8]+[4,32,8] is needed\n",
    "    - in fact, [4,32,8]+[5.0] is convenient\n",
    "2. memory consumption\n",
    "    - [4,32,8] ==> 1024\n",
    "    - [5.0] ==> 1\n",
    "\n",
    "### is it broadcasting-able?\n",
    "- match from <font color=red>**last**</font> dim!\n",
    "    - if current dim = 1, expand to same\n",
    "    - if either has no dim, insert one dim and expand to same\n",
    "    - otherwise, NOT broadcasting-able\n",
    "\n",
    "## Merge or Split\n",
    "- cat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 32, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 32, 8)\n",
    "b = torch.rand(5, 32, 8)\n",
    "print(torch.cat([a, b], dim=0).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- stack: create new dim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 3, 2, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 3, 16, 32)\n",
    "b = torch.rand(4, 3, 16, 32)\n",
    "print(torch.cat([a, b], dim=2).shape)\n",
    "# when stack, a and b have the same dim\n",
    "print(torch.stack([a, b], dim=2).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- split: by length or number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n",
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "aa, bb = c.split([1, 1], dim=0)  # number of each split\n",
    "print(aa.shape, bb.shape)\n",
    "aa, bb = c.split(1, dim=0)  # length\n",
    "print(aa.shape, bb.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- chunk: by output number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 8]) torch.Size([1, 32, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(32, 8)\n",
    "b = torch.rand(32, 8)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "aa, bb = c.chunk(2, dim=0)  # output number\n",
    "print(aa.shape, bb.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## math operation\n",
    "- add/minus/multiply/divide\n",
    "- matmul\n",
    "- pow\n",
    "- sqrt/rsqrt\n",
    "- round\n",
    "\n",
    "### basic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1005, 0.6229, 1.6519, 1.2822],\n",
      "        [0.3442, 0.6109, 1.5206, 0.8659],\n",
      "        [0.5469, 1.0048, 1.6472, 0.7928]])\n",
      "tensor([[0.1005, 0.6229, 1.6519, 1.2822],\n",
      "        [0.3442, 0.6109, 1.5206, 0.8659],\n",
      "        [0.5469, 1.0048, 1.6472, 0.7928]])\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(3, 4)\n",
    "b = torch.rand(4)\n",
    "print(a + b)\n",
    "print(torch.add(a, b))\n",
    "print(torch.all(torch.eq(a - b, torch.sub(a, b))))\n",
    "print(torch.all(torch.eq(a * b, torch.mul(a, b))))\n",
    "print(torch.all(torch.eq(a / b, torch.div(a, b))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### matmul\n",
    "- `torch.mm`\n",
    "- `torch.matmul`\n",
    "- `@`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "b= tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "a mm b =  tensor([[12., 12.],\n",
      "        [12., 12.]])\n",
      "a matmul b =  tensor([[12., 12.],\n",
      "        [12., 12.]])\n",
      "a @ b =  tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[3., 3.], [3., 3.]])\n",
    "print(\"a=\", a)\n",
    "b = torch.ones(2, 2) * 2\n",
    "print(\"b=\", b)\n",
    "print(\"a mm b = \", torch.mm(a, b))\n",
    "print(\"a matmul b = \", torch.matmul(a, b))\n",
    "print(\"a @ b = \", a @ b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### an example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(4, 784)\n",
    "x = torch.rand(4, 784)\n",
    "w = torch.rand(512, 784)\n",
    "# to descent dim from 784 to 512\n",
    "print((x @ w.t()).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## statistics\n",
    "- norm\n",
    "- mean sum\n",
    "- prod\n",
    "- max,min,argmin,argmax\n",
    "- kthvalue,topk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}