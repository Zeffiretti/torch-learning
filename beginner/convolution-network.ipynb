{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# convolution network\r\n",
    "\r\n",
    "## description in textbook\r\n",
    "\r\n",
    "- continous form\r\n",
    "  \r\n",
    "$\\begin{equation*}\r\n",
    "(f*g)(n)=∫_{-∞}^{∞}f{τ}g(n-τ)dτ\r\n",
    "\\end{equation*}$\r\n",
    "\r\n",
    "- discrete from\r\n",
    "\r\n",
    "$\\begin{equation*}\r\n",
    "(f*g)(n)=∑_{τ=-∞}^{∞}f{τ}g(n-τ)\r\n",
    "\\end{equation*}$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "对卷积这个名词的理解：**所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加。**\r\n",
    "\r\n",
    "参考[知乎](https://www.zhihu.com/question/22298352)回答。\r\n",
    "\r\n",
    "**瞬时行为的持续性后果**\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 2d convolution\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "x = torch.rand(1, 3, 28, 28)\r\n",
    "# parameters 1st: 3, input has 3 channels\r\n",
    "# parameters 2nd: 3, output has 3 channels\r\n",
    "layer = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\r\n",
    "out = layer.forward(x)\r\n",
    "print(\"padding=0\", out.size())\r\n",
    "\r\n",
    "# [b,1,28,28] == kernel[3,1,3,3] ==> [1,2,28,28]\r\n",
    "out = layer.forward(x)\r\n",
    "print(\"padding=1\", out.size())\r\n",
    "\r\n",
    "# convenient way\r\n",
    "out = layer(x)  #.__call__\r\n",
    "print(\"convenient\", out.size())\r\n",
    "\r\n",
    "# some information\r\n",
    "print(\"layer.weight\", layer.weight)\r\n",
    "print(\"layer.bias\", layer.bias)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "padding=0 torch.Size([1, 3, 28, 28])\n",
      "padding=1 torch.Size([1, 3, 28, 28])\n",
      "convenient torch.Size([1, 3, 28, 28])\n",
      "layer.weight Parameter containing:\n",
      "tensor([[[[-0.0315,  0.0885,  0.0659],\n",
      "          [ 0.0216, -0.1016,  0.0011],\n",
      "          [ 0.1141, -0.0933, -0.1203]],\n",
      "\n",
      "         [[-0.1121,  0.0020,  0.1166],\n",
      "          [-0.0271,  0.0315, -0.0622],\n",
      "          [ 0.1611,  0.0671,  0.1478]],\n",
      "\n",
      "         [[ 0.1047, -0.0065,  0.1638],\n",
      "          [ 0.0945, -0.1282, -0.0828],\n",
      "          [ 0.1281, -0.1003, -0.0865]]],\n",
      "\n",
      "\n",
      "        [[[-0.1422, -0.1166, -0.0918],\n",
      "          [-0.0167,  0.1351, -0.1817],\n",
      "          [-0.0331,  0.1771, -0.1429]],\n",
      "\n",
      "         [[ 0.1405,  0.0679, -0.0774],\n",
      "          [-0.1561, -0.0875, -0.0400],\n",
      "          [-0.0537,  0.0367, -0.1841]],\n",
      "\n",
      "         [[-0.1595,  0.0247, -0.1373],\n",
      "          [ 0.1016,  0.0223,  0.0657],\n",
      "          [-0.0454,  0.1220, -0.1142]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0137, -0.0186, -0.0910],\n",
      "          [ 0.1029,  0.1110,  0.1907],\n",
      "          [ 0.0869,  0.0613,  0.1082]],\n",
      "\n",
      "         [[ 0.1158, -0.1820, -0.1821],\n",
      "          [-0.1748,  0.0913,  0.0057],\n",
      "          [-0.0732, -0.0922, -0.1597]],\n",
      "\n",
      "         [[-0.0421,  0.0906,  0.0028],\n",
      "          [-0.0362,  0.1730, -0.0066],\n",
      "          [ 0.0823,  0.0626,  0.0662]]]], requires_grad=True)\n",
      "layer.bias Parameter containing:\n",
      "tensor([-0.0092, -0.1460, -0.0387], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# low-level usage\r\n",
    "\r\n",
    "from torch.nn import functional as F\r\n",
    "import torch\r\n",
    "\r\n",
    "x = torch.rand(1, 3, 28, 28)\r\n",
    "w = torch.rand(16, 3, 5, 5)\r\n",
    "b = torch.rand(16)\r\n",
    "out = F.conv2d(x, w, b, stride=1, padding=1)\r\n",
    "print(\"out\", out.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "out torch.Size([1, 16, 26, 26])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Max pooling & Subsampling\r\n",
    "\r\n",
    "## Batch Normalization\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\r\n",
    "\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "x = torch.rand(100, 16, 784)  # 28*28\r\n",
    "layer = nn.BatchNorm1d(16)\r\n",
    "out = layer(x)\r\n",
    "print(\"layer.running_mean\", layer.running_mean)\r\n",
    "print(\"layer.running_var\", layer.running_var)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "layer.running_mean tensor([0.0499, 0.0499, 0.0502, 0.0501, 0.0500, 0.0501, 0.0502, 0.0499, 0.0499,\n",
      "        0.0500, 0.0502, 0.0500, 0.0499, 0.0501, 0.0499, 0.0501])\n",
      "layer.running_var tensor([0.9083, 0.9083, 0.9083, 0.9083, 0.9083, 0.9084, 0.9084, 0.9083, 0.9083,\n",
      "        0.9083, 0.9084, 0.9083, 0.9083, 0.9083, 0.9084, 0.9083])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torch import nn\r\n",
    "from torch.nn import functional as F\r\n",
    "\r\n",
    "\r\n",
    "class ResBlk(nn.Module):\r\n",
    "    def __init__(self, ch_in, ch_out):\r\n",
    "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\r\n",
    "        self.conv2 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1)\r\n",
    "        self.bn2 = nn.BatchNorm2d(ch_out)\r\n",
    "\r\n",
    "        self.extra = nn.Sequential()\r\n",
    "        if ch_out != ch_in:\r\n",
    "            # [b,ch_in,h,w] ==> [b,ch_out,h,w]\r\n",
    "            self.extra = nn.Sequential(\r\n",
    "                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1),\r\n",
    "                nn.BatchNorm2d(ch_out))\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
    "        out = self.bn2(self.conv2(out))\r\n",
    "        out = self.extra(x) + out\r\n",
    "        return out\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "f66bf51fd447f76575480c1dc7315469d276039bb74f2fe747b2cf835f229b51"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}